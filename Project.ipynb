{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likhithluck/Capstone-Project/blob/tarun/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!pip install datasets\n",
        "!pip install pytesseract\n",
        "!pip install pdfplumber\n",
        "!apt-get install tesseract-ocr\n",
        "!apt-get install libtesseract-dev\n",
        "!apt-get install poppler-utils # Install poppler-utils which includes pdfinfo\n"
      ],
      "metadata": {
        "id": "1B39cARByiv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c192ff11-628d-4d11-ac08-13859a82d71b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.4.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (24.2 MB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.3 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 0s (22.4 MB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 125091 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 0s (2,041 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 125224 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as panda\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from PIL import Image as img\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import pdfplumber\n",
        "from google.colab import files\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ],
      "metadata": {
        "id": "HXR02Hi0uGbv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key=userdata.get('hugging_face_key')"
      ],
      "metadata": {
        "id": "xOeEYz2owsN_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "login(token=key)"
      ],
      "metadata": {
        "id": "gvbXqrsnynzB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset1 = load_dataset('mychen76/invoices-and-receipts_ocr_v1')\n",
        "# dataset2 = load_dataset('mychen76/invoices-and-receipts_ocr_v2')"
      ],
      "metadata": {
        "id": "gPBpj1fFz2fC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Basic OCR\n",
        "# # Preprocessing Function\n",
        "# def preprocess_image(image):\n",
        "#     gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
        "#     denoised = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
        "#     clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
        "#     contrast_enhanced = clahe.apply(denoised)\n",
        "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "#     cleaned = cv2.morphologyEx(contrast_enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "#     thresh = cv2.adaptiveThreshold(cleaned, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "#                                    cv2.THRESH_BINARY, 11, 2)\n",
        "#     return thresh\n",
        "\n",
        "\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     images = convert_from_path(pdf_path, dpi=300 ,poppler_path=\"/usr/bin\" )\n",
        "\n",
        "#     extracted_text = \"\"\n",
        "\n",
        "#     for i, image in enumerate(images):\n",
        "#         processed_image = preprocess_image(image)\n",
        "#         custom_config = '--psm 6 --oem 3'\n",
        "#         page_text = pytesseract.image_to_string(processed_image, config=custom_config)\n",
        "#         extracted_text += f\"\\n--- Page {i + 1} ---\\n{page_text}\"\n",
        "\n",
        "#     print(\"Extracted Text:\\n\", extracted_text)\n",
        "\n",
        "\n",
        "# #Dataset pdf\n",
        "# pdf_path = \"/content/invoice_Yana Sorensen_5434.pdf\"\n",
        "# #OCR extraction\n",
        "# text=extract_text_from_pdf(pdf_path)\n",
        "# print(text)"
      ],
      "metadata": {
        "id": "GavwpAbp80OJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def extract_clean_text(pdf_path):\n",
        "#     clean_text = \"\"\n",
        "#     with pdfplumber.open(pdf_path) as pdf:\n",
        "#         for page_num, page in enumerate(pdf.pages):\n",
        "#             text = page.extract_text()\n",
        "#             if text:\n",
        "#                 clean_text += text.strip() + \"\\n\\n\"\n",
        "#     print(clean_text)\n",
        "#     with open(\"clean_text_output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "#         file.write(clean_text)\n",
        "\n",
        "# # Path to PDF\n",
        "# pdf_path = \"/content/invoice_Yana Sorensen_5434.pdf\"\n",
        "\n",
        "# # Run Extraction\n",
        "# ocr_pdf_plum=extract_clean_text(pdf_path)\n"
      ],
      "metadata": {
        "id": "oh3G2ovCcDE1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#upload file\n",
        "def upload_pdf():\n",
        "    uploaded = files.upload()\n",
        "    pdf_path = next(iter(uploaded))\n",
        "    return pdf_path\n",
        "\n",
        "#preprocess the image\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
        "    sharpened = cv2.filter2D(gray, -1, np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]))\n",
        "    denoised = cv2.fastNlMeansDenoising(sharpened, None, 30, 7, 21)\n",
        "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
        "    contrast_enhanced = clahe.apply(denoised)\n",
        "    return contrast_enhanced\n",
        "\n",
        "\n",
        "#OCR Extraction\n",
        "def extract_text_with_ocr(pdf_path):\n",
        "    extracted_text = \"\"\n",
        "    images = convert_from_path(pdf_path, dpi=300, poppler_path=\"/usr/bin\")\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        processed_image = preprocess_image(image)\n",
        "        custom_config = '--psm 3 --oem 3'\n",
        "        page_text = pytesseract.image_to_string(processed_image, config=custom_config)\n",
        "        extracted_text += f\"--- Page {i + 1} ---\\n{page_text.strip()}\\n\\n\"\n",
        "\n",
        "    return extracted_text\n",
        "\n",
        "# Table Extraction Using pdfplumber\n",
        "def extract_tables_from_pdf(pdf_path):\n",
        "    table_data = \"\"\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages):\n",
        "\n",
        "            # Adjust table settings\n",
        "            tables = page.extract_tables(\n",
        "                table_settings={\n",
        "                    \"snap_tolerance\": 10,\n",
        "                    \"join_tolerance\": 10,  # Merges fragmented rows\n",
        "                    \"edge_min_length\": 50, # Filters out small text artifacts\n",
        "                    \"horizontal_strategy\": \"lines\",  # Try extracting text as lines\n",
        "                    \"vertical_strategy\": \"lines\",  # Strategy to align vertically\n",
        "                }\n",
        "            )\n",
        "\n",
        "\n",
        "            if tables:\n",
        "                table_data += f\"\\n--- Tables from Page {page_num + 1} ---\\n\"\n",
        "                for table in tables:\n",
        "                    for row in table:\n",
        "\n",
        "                        cleaned_row = [str(cell).strip() if cell else '' for cell in row]\n",
        "                        table_data += \" | \".join(cleaned_row) + \"\\n\"\n",
        "            else:\n",
        "                print(\"No table found on this page.\")\n",
        "\n",
        "    return table_data\n",
        "\n",
        "\n",
        "def extract_data(pdf_path):\n",
        "    print(\"(OCR)\")\n",
        "    ocr_text = extract_text_with_ocr(pdf_path)\n",
        "\n",
        "    print(\"\\nTables\")\n",
        "    table_data = extract_tables_from_pdf(pdf_path)\n",
        "\n",
        "    return ocr_text, table_data\n",
        "\n",
        "\n",
        "#Testing\n",
        "# pdf_path = \"/content/invoice_Yana Sorensen_5434.pdf\"\n",
        "pdf_path=upload_pdf()\n",
        "ocr_text, table_data = extract_data(pdf_path)\n",
        "\n",
        "print(\"\\nOCR Text\\n\")\n",
        "print(ocr_text)\n",
        "print(table_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "qAlaE4nyarkN",
        "outputId": "2b454b2c-b7c1-4db7-b8e3-67208ec80bf1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-59a0b73a-6016-4417-b391-f3158bc8a32f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-59a0b73a-6016-4417-b391-f3158bc8a32f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving invoice_Sandra Glassco_27994.pdf to invoice_Sandra Glassco_27994.pdf\n",
            "(OCR)\n",
            "\n",
            "Tables\n",
            "No table found on this page.\n",
            "\n",
            "OCR Text\n",
            "\n",
            "--- Page 1 ---\n",
            "Superstore INVOICE\n",
            "\n",
            "# 27994\n",
            "Date: Oct 26 2012\n",
            "Bill To: Ship To:\n",
            "Ship Mode: Standard Class\n",
            "Sandra Glassco Gorakhpur, Haryana,\n",
            "India Balance Due: $11,641.02\n",
            "Item | Quantity Bcclte) Amount\n",
            "Bush 3-Shelf Cabinet, Metal 9 $1,285.47 $11,569.23\n",
            "Bookcases, Furniture, FUR-BO-3615\n",
            "Subtotal: $11,569.23\n",
            "Shipping: $71.79\n",
            "Total: $11,641.02\n",
            "\n",
            "Notes:\n",
            "Thanks for your business!\n",
            "\n",
            "Terms:\n",
            "Order ID : IN-2012-SG2008058-41208\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the types of ocr_text and table_data\n",
        "ocr_text_type = type(ocr_text)\n",
        "table_data_type = type(table_data)\n",
        "\n",
        "extracted_data = {\n",
        "    'ocr_text': ocr_text,\n",
        "    'table_data': table_data\n",
        "}\n"
      ],
      "metadata": {
        "id": "1gXru70abIed"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqKKsOFjnBVl",
        "outputId": "950b89e8-32b4-452f-cdf2-f6999f2dfa24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ocr_text': '--- Page 1 ---\\nSuperstore INVOICE\\n\\n# 27994\\nDate: Oct 26 2012\\nBill To: Ship To:\\nShip Mode: Standard Class\\nSandra Glassco Gorakhpur, Haryana,\\nIndia Balance Due: $11,641.02\\nItem | Quantity Bcclte) Amount\\nBush 3-Shelf Cabinet, Metal 9 $1,285.47 $11,569.23\\nBookcases, Furniture, FUR-BO-3615\\nSubtotal: $11,569.23\\nShipping: $71.79\\nTotal: $11,641.02\\n\\nNotes:\\nThanks for your business!\\n\\nTerms:\\nOrder ID : IN-2012-SG2008058-41208\\n\\n',\n",
              " 'table_data': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example OCR text\n",
        "# ocr_text = \"\"\"\n",
        "# Superstore INVOICE\n",
        "\n",
        "# # 5434\n",
        "# Date: May 31 2012\n",
        "# Bill To: Ship To:\n",
        "# Ship Mode: Standard Class\n",
        "# Yana Sorensen Matagalpa,\n",
        "# Matagalpa, Nicaragua Balance Due: $1,031.66\n",
        "# Item | Quantity Bcc) Amount\n",
        "# Dania Library with Doors, Metal 2 $482.48 $964.96\n",
        "# Bookcases, Furniture, FUR-BO-3901\n",
        "# Subtotal: $964.96\n",
        "# Shipping: $66.70\n",
        "# Total: $1,031.66\n",
        "\n",
        "# Notes:\n",
        "# Thanks for your business!\n",
        "\n",
        "# Terms:\n",
        "# Order ID : MX-2012-YS21 88093-41060\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "6tn3UKCl3vgn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84PR3NkdnZ3t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy's pre-trained NER model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def perform_ner(text):\n",
        "    doc = nlp(text)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append({\n",
        "            \"text\": ent.text,\n",
        "            \"label\": ent.label_,\n",
        "            \"start_char\": ent.start_char,\n",
        "            \"end_char\": ent.end_char\n",
        "        })\n",
        "    return entities\n",
        "\n",
        "\n",
        "ner_results = perform_ner(ocr_text)\n"
      ],
      "metadata": {
        "id": "DKj68U63hCH_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def ocr_to_json_with_ner(ocr_text, ner_results):\n",
        "    # Initialize variables\n",
        "    invoice_data = {\n",
        "        \"invoice_number\": None,\n",
        "        \"date\": None,\n",
        "        \"bill_to\": None,\n",
        "        \"ship_to\": None,\n",
        "        \"ship_mode\": None,\n",
        "        \"balance_due\": None,\n",
        "        \"items\": [],\n",
        "        \"subtotal\": None,\n",
        "        \"discount\": None,\n",
        "        \"shipping\": None,\n",
        "        \"total\": None,\n",
        "        \"notes\": \"\",\n",
        "        \"terms\": {\"order_id\": None}\n",
        "    }\n",
        "\n",
        "    #Items\n",
        "    item = []\n",
        "\n",
        "\n",
        "    # Extract entities and populate the JSON structure\n",
        "    person_entities = [entity for entity in ner_results if entity[\"label\"] == \"PERSON\"]\n",
        "    # gpe_entities = [entity for entity in ner_results if entity[\"label\"] == \"GPE\"]\n",
        "    date_entities = [entity for entity in ner_results if entity[\"label\"] == \"DATE\"]\n",
        "    invoice_entities = [entity for entity in ner_results if entity[\"label\"] == \"MONEY\"]\n",
        "\n",
        "    # Assign the first PERSON entity to bill_to\n",
        "    if len(person_entities) >= 1:\n",
        "        invoice_data[\"bill_to\"] = person_entities[2][\"text\"]\n",
        "    # DATE\n",
        "    if len(date_entities) >= 1:\n",
        "        invoice_data[\"date\"] = date_entities[0][\"text\"]\n",
        "    # INVOICE NUM\n",
        "    if len(invoice_entities) >= 1:\n",
        "        invoice_data[\"invoice_number\"] = invoice_entities[0][\"text\"]\n",
        "\n",
        "    # Assign ship_to based on bill_to value\n",
        "    if invoice_data[\"bill_to\"]:\n",
        "        # Search for the bill_to value in the OCR text\n",
        "        bill_to_index = ocr_text.find(invoice_data[\"bill_to\"])\n",
        "        if bill_to_index != -1:\n",
        "            # Extract the text after the bill_to value\n",
        "            text_after_bill_to = ocr_text[bill_to_index + len(invoice_data[\"bill_to\"]):]\n",
        "            # Find the text before \"Balance Due\"\n",
        "            balance_due_index = text_after_bill_to.find(\"Balance Due\")\n",
        "            if balance_due_index != -1:\n",
        "                # Extract the ship_to value (text between the comma after bill_to and \"Balance Due\")\n",
        "                ship_to_value = text_after_bill_to[:balance_due_index].strip()\n",
        "                # Remove any leading/trailing punctuation\n",
        "                ship_to_value = ship_to_value.strip(\", \")\n",
        "                # Clean the ship_to value by removing \": \" and \"\\n\"\n",
        "                ship_to_value = ship_to_value.replace(\": \", \"\").replace(\"\\n\", \" \")\n",
        "                invoice_data[\"ship_to\"] = ship_to_value\n",
        "\n",
        "    # Extract Ship Mode using regex\n",
        "    ship_mode_match = re.search(r\"Ship Mode: ([\\w\\s]+)\\n\", ocr_text)\n",
        "    if ship_mode_match:\n",
        "        ship_mode = ship_mode_match.group(1).strip()\n",
        "        invoice_data[\"ship_mode\"] = ship_mode\n",
        "\n",
        "    # Extract Balance Due using regex\n",
        "    balance_due_match = re.search(r\"Balance Due: \\$([\\d,]+\\.\\d{2})\", ocr_text)\n",
        "    if balance_due_match:\n",
        "        balance_due = balance_due_match.group(1).strip()\n",
        "        invoice_data[\"balance_due\"] = float(balance_due.replace(\",\", \"\"))\n",
        "\n",
        "    # Extract Subtotal using regex\n",
        "    subtotal_match = re.search(r\"Subtotal: \\$([\\d,]+\\.\\d{2})\", ocr_text)\n",
        "    if subtotal_match:\n",
        "      subtotal = subtotal_match.group(1).strip()\n",
        "      invoice_data[\"subtotal\"] = float(subtotal.replace(\",\", \"\"))\n",
        "\n",
        "    # Extract Discount using regex (assuming discount is labeled as \"Discount\" or \"Discount (20%)\")\n",
        "    discount_match = re.search(r\"Discount \\(?\\d*%?\\)?: \\$([\\d,]+\\.\\d{2})\", ocr_text)\n",
        "    if discount_match:\n",
        "        discount = discount_match.group(1).strip()\n",
        "        invoice_data[\"discount\"] = float(discount.replace(\",\", \"\"))\n",
        "\n",
        "    # Extract Shipping using regex\n",
        "    shipping_match = re.search(r\"Shipping: \\$([\\d,]+\\.\\d{2})\", ocr_text)\n",
        "    if shipping_match:\n",
        "        shipping = shipping_match.group(1).strip()\n",
        "        invoice_data[\"shipping\"] = float(shipping.replace(\",\", \"\"))\n",
        "\n",
        "    # Extract Total using regex\n",
        "    total_match = re.search(r\"Total: \\$([\\d,]+\\.\\d{2})\", ocr_text)\n",
        "    if total_match:\n",
        "        total = total_match.group(1).strip()\n",
        "        invoice_data[\"total\"] = float(total.replace(\",\", \"\"))\n",
        "\n",
        "\n",
        "    # Extract Notes (text after \"Notes:\" until the next \"Terms:\" or end of text)\n",
        "    notes_match = re.search(r\"Notes:\\s*(.*?)\\s*(?=Terms:|$)\", ocr_text, re.DOTALL)\n",
        "    if notes_match:\n",
        "        notes = notes_match.group(1).strip()\n",
        "        invoice_data[\"notes\"] = notes\n",
        "\n",
        "    # Extract Order ID (text after \"Order ID :\")\n",
        "    order_id_match = re.search(r\"Order ID : (\\S+)\", ocr_text)\n",
        "    if order_id_match:\n",
        "        order_id = order_id_match.group(1).strip()\n",
        "        invoice_data[\"terms\"][\"order_id\"] = order_id+date_entities[-1][\"text\"]\n",
        "\n",
        "    # Regex to match item lines\n",
        "   # item_pattern = re.compile(r\"([\\w\\s]+)\\s+(\\d+)\\s+\\$([\\d,]+\\.\\d{2})\\s+\\$([\\d,]+\\.\\d{2})\")\n",
        "    # Regex to match item lines\n",
        "    item_pattern = re.compile(r\"([\\w\\s\\-,]+)\\s+(\\d+)\\s+\\$([\\d,]+\\.\\d{2})\\s+\\$([\\d,]+\\.\\d{2})\")\n",
        "\n",
        "    # Find all matches in the OCR text\n",
        "    matches = item_pattern.findall(ocr_text)\n",
        "\n",
        "    # Process each match\n",
        "    for match in matches:\n",
        "        item_name = match[0].strip()\n",
        "        item_name = re.sub(r\"Amount\\n\", \"\", item_name).strip()\n",
        "        quantity = int(match[1].strip())\n",
        "        unit_price = float(match[2].replace(\",\", \"\").strip())\n",
        "        total_price = float(match[3].replace(\",\", \"\").strip())\n",
        "\n",
        "        # Add the item to the list\n",
        "        item.append({\n",
        "            \"item_name\": item_name,\n",
        "            \"quantity\": quantity,\n",
        "            \"unit_price\": unit_price,\n",
        "            \"total_price\": total_price\n",
        "        })\n",
        "    invoice_data[\"items\"] = item\n",
        "\n",
        "    return json.dumps({\"invoice\": invoice_data}, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "json_output = ocr_to_json_with_ner(ocr_text, ner_results)\n",
        "print(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-4H7Vu4uZ8Y",
        "outputId": "3dfa1e2b-010e-43f5-8498-3bcc5bb4df39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"invoice\": {\n",
            "        \"invoice_number\": \"27994\",\n",
            "        \"date\": \"26 2012\",\n",
            "        \"bill_to\": \"Sandra Glassco Gorakhpur\",\n",
            "        \"ship_to\": \"Haryana, India\",\n",
            "        \"ship_mode\": \"Standard Class\",\n",
            "        \"balance_due\": 11641.02,\n",
            "        \"items\": [\n",
            "            {\n",
            "                \"item_name\": \"Bush 3-Shelf Cabinet, Metal\",\n",
            "                \"quantity\": 9,\n",
            "                \"unit_price\": 1285.47,\n",
            "                \"total_price\": 11569.23\n",
            "            }\n",
            "        ],\n",
            "        \"subtotal\": 11569.23,\n",
            "        \"discount\": null,\n",
            "        \"shipping\": 71.79,\n",
            "        \"total\": 11641.02,\n",
            "        \"notes\": \"Thanks for your business!\",\n",
            "        \"terms\": {\n",
            "            \"order_id\": \"IN-2012-SG2008058-4120841208\"\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "def extract_items(ocr_text):\n",
        "    # Initialize items list\n",
        "    items = []\n",
        "\n",
        "    # Regex to match item lines\n",
        "    item_pattern = re.compile(r\"([\\w\\s]+)\\s+(\\d+)\\s+\\$([\\d,]+\\.\\d{2})\\s+\\$([\\d,]+\\.\\d{2})\")\n",
        "\n",
        "    # Find all matches in the OCR text\n",
        "    matches = item_pattern.findall(ocr_text)\n",
        "\n",
        "    # Process each match\n",
        "    for match in matches:\n",
        "        item_name = match[0].strip()\n",
        "        quantity = int(match[1].strip())\n",
        "        unit_price = float(match[2].replace(\",\", \"\").strip())\n",
        "        total_price = float(match[3].replace(\",\", \"\").strip())\n",
        "\n",
        "        # Add the item to the list\n",
        "        items.append({\n",
        "            \"item_name\": item_name,\n",
        "            \"quantity\": quantity,\n",
        "            \"unit_price\": unit_price,\n",
        "            \"total_price\": total_price\n",
        "        })\n",
        "\n",
        "\n",
        "    return items\n",
        "\n",
        "\n",
        "# Extract items\n",
        "items = extract_items(ocr_text)\n",
        "\n",
        "# Print the items\n",
        "print(items)"
      ],
      "metadata": {
        "id": "rLEukKVxvFXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f88dd61-509c-4cf8-d2ec-ec372acfd162"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'item_name': 'Amount\\nSmead Shelving', 'quantity': 12, 'unit_price': 492.12, 'total_price': 5905.48}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zu9op42dCgQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}